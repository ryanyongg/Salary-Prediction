{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using: /Users/yongryan/Downloads/bigdataryan /artifacts/cleaned/employee_full_clean.csv | sklearn: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "#cell 1: Setup \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import __version__ as sklearn_version\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_PATH = Path(\"artifacts/cleaned/employee_full_clean.csv\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "assert DATA_PATH.exists(), f\"Missing file: {DATA_PATH.resolve()}\"\n",
    "print(\"Setup complete. Using:\", DATA_PATH.resolve(), \"| sklearn:\", sklearn_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 999,895 rows × 12 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>job_role</th>\n",
       "      <th>education</th>\n",
       "      <th>major</th>\n",
       "      <th>industry</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>distance_from_cbd</th>\n",
       "      <th>is_outlier_years_experience</th>\n",
       "      <th>is_outlier_distance_from_cbd</th>\n",
       "      <th>salary_in_thousands</th>\n",
       "      <th>is_outlier_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOB1362684407687</td>\n",
       "      <td>COMP37</td>\n",
       "      <td>CFO</td>\n",
       "      <td>MASTER</td>\n",
       "      <td>MATH</td>\n",
       "      <td>HEALTH</td>\n",
       "      <td>10.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>130.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOB1362684407688</td>\n",
       "      <td>COMP19</td>\n",
       "      <td>CEO</td>\n",
       "      <td>HIGH_SCHOOL</td>\n",
       "      <td>NONE</td>\n",
       "      <td>WEB</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>101.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JOB1362684407697</td>\n",
       "      <td>COMP56</td>\n",
       "      <td>JANITOR</td>\n",
       "      <td>HIGH_SCHOOL</td>\n",
       "      <td>NONE</td>\n",
       "      <td>HEALTH</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>102.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOB1362684407698</td>\n",
       "      <td>COMP7</td>\n",
       "      <td>CEO</td>\n",
       "      <td>MASTER</td>\n",
       "      <td>PHYSICS</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>7.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>144.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB1362684407699</td>\n",
       "      <td>COMP4</td>\n",
       "      <td>JUNIOR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>OIL</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>79.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_id company_id job_role    education    major   industry  \\\n",
       "0  JOB1362684407687     COMP37      CFO       MASTER     MATH     HEALTH   \n",
       "1  JOB1362684407688     COMP19      CEO  HIGH_SCHOOL     NONE        WEB   \n",
       "2  JOB1362684407697     COMP56  JANITOR  HIGH_SCHOOL     NONE     HEALTH   \n",
       "3  JOB1362684407698      COMP7      CEO       MASTER  PHYSICS  EDUCATION   \n",
       "4  JOB1362684407699      COMP4   JUNIOR         NONE     NONE        OIL   \n",
       "\n",
       "   years_experience  distance_from_cbd  is_outlier_years_experience  \\\n",
       "0              10.0               83.0                        False   \n",
       "1               3.0               73.0                        False   \n",
       "2              24.0               30.0                        False   \n",
       "3               7.0               79.0                        False   \n",
       "4               8.0               29.0                        False   \n",
       "\n",
       "   is_outlier_distance_from_cbd  salary_in_thousands is_outlier_salary  \n",
       "0                         False                130.0             False  \n",
       "1                         False                101.0             False  \n",
       "2                         False                102.0             False  \n",
       "3                         False                144.0             False  \n",
       "4                         False                 79.0             False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cell 2: Load Cleaned Data\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "print(f\"Loaded: {df.shape[0]:,} rows × {df.shape[1]} cols\")\n",
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " is_outlier_salary               225\n",
      "salary_in_thousands             225\n",
      "job_id                            0\n",
      "company_id                        0\n",
      "education                         0\n",
      "job_role                          0\n",
      "major                             0\n",
      "industry                          0\n",
      "distance_from_cbd                 0\n",
      "years_experience                  0\n",
      "is_outlier_distance_from_cbd      0\n",
      "is_outlier_years_experience       0\n",
      "dtype: int64\n",
      "\n",
      "Dtypes:\n",
      " job_id                           object\n",
      "company_id                       object\n",
      "job_role                         object\n",
      "education                        object\n",
      "major                            object\n",
      "industry                         object\n",
      "years_experience                float64\n",
      "distance_from_cbd               float64\n",
      "is_outlier_years_experience        bool\n",
      "is_outlier_distance_from_cbd       bool\n",
      "salary_in_thousands             float64\n",
      "is_outlier_salary                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#cell 3: Sanity Checks (post-cleaning) + Normalize flag dtypes \n",
    "print(\"Missing values per column:\\n\", df.isna().sum().sort_values(ascending=False).head(20))\n",
    "print(\"\\nDtypes:\\n\", df.dtypes)\n",
    "\n",
    "required_cols = [\n",
    "    \"job_id\",\"company_id\",\"job_role\",\"education\",\"major\",\"industry\",\n",
    "    \"years_experience\",\"distance_from_cbd\",\"salary_in_thousands\"\n",
    "]\n",
    "missing_required = [c for c in required_cols if c not in df.columns]\n",
    "assert not missing_required, f\"Missing expected columns: {missing_required}\"\n",
    "\n",
    "# job_id check as a warning (some datasets use a different format)\n",
    "id_ok = df[\"job_id\"].astype(str).str.match(r\"^JOB\\d+$\", na=False).mean()\n",
    "if id_ok < 0.95:\n",
    "    print(f\"WARNING: job_id pattern 'JOB###' found in only {100*id_ok:.1f}% of rows. Proceeding.\")\n",
    "\n",
    "# normalise outlier flags to clean booleans (even if unused as features)\n",
    "for c in [\"is_outlier_years_experience\", \"is_outlier_distance_from_cbd\", \"is_outlier_salary\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].map({True: True, False: False, \"True\": True, \"False\": False})\n",
    "        df[c] = df[c].fillna(False).astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: ['company_id', 'job_role', 'education', 'major', 'industry']\n",
      "Numeric: ['years_experience', 'distance_from_cbd']\n",
      "Outlier flags: ['is_outlier_years_experience', 'is_outlier_distance_from_cbd', 'is_outlier_salary']\n"
     ]
    }
   ],
   "source": [
    "#cell 4: define feature groups \n",
    "target = \"salary_in_thousands\"\n",
    "\n",
    "categorical_cols = [\"company_id\", \"job_role\", \"education\", \"major\", \"industry\"]\n",
    "numeric_cols = [\"years_experience\", \"distance_from_cbd\"]\n",
    "\n",
    "# outlier flags created during cleaning \n",
    "outlier_cols = [c for c in [\"is_outlier_years_experience\", \"is_outlier_distance_from_cbd\", \"is_outlier_salary\"] if c in df.columns]\n",
    "\n",
    "print(\"Categorical:\", categorical_cols)\n",
    "print(\"Numeric:\", numeric_cols)\n",
    "print(\"Outlier flags:\", outlier_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   years_experience exp_level  distance_from_cbd  near_cbd\n",
      "0              10.0       mid               83.0         0\n",
      "1               3.0    junior               73.0         0\n",
      "2              24.0    senior               30.0         0\n",
      "3               7.0       mid               79.0         0\n",
      "4               8.0       mid               29.0         0\n"
     ]
    }
   ],
   "source": [
    "#cell 5: feature Engineering (core) \n",
    "df = df.copy()\n",
    "\n",
    "# 1) log-transform target for skewness (for diagnostics/option later; not used as X)\n",
    "df[\"log_salary\"] = np.log1p(df[target])\n",
    "\n",
    "# 2) Experience buckets\n",
    "df[\"exp_level\"] = pd.cut(\n",
    "    df[\"years_experience\"],\n",
    "    bins=[-1, 5, 15, np.inf],\n",
    "    labels=[\"junior\", \"mid\", \"senior\"]\n",
    ")\n",
    "\n",
    "# 3) cbd proximity flag (binary engineered numeric; we'll passthrough unscaled)\n",
    "df[\"near_cbd\"] = (df[\"distance_from_cbd\"] < 10).astype(int)\n",
    "\n",
    "# lock categorical dtypes for stable OHE\n",
    "for c in [\"company_id\",\"job_role\",\"education\",\"major\",\"industry\",\"exp_level\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(\"category\")\n",
    "\n",
    "print(df[[\"years_experience\",\"exp_level\",\"distance_from_cbd\",\"near_cbd\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added interactions: ['edu_industry', 'role_exp']\n"
     ]
    }
   ],
   "source": [
    "#cell 6: (Optional) Interactions \n",
    "ADD_INTERACTIONS = True  # set false to get minimal features\n",
    "\n",
    "if ADD_INTERACTIONS:\n",
    "    if {\"education\",\"industry\"}.issubset(df.columns):\n",
    "        df[\"edu_industry\"] = (df[\"education\"].astype(str) + \"__\" + df[\"industry\"].astype(str))\n",
    "        df[\"edu_industry\"] = df[\"edu_industry\"].astype(\"category\")\n",
    "    if {\"job_role\",\"exp_level\"}.issubset(df.columns):\n",
    "        df[\"role_exp\"] = (df[\"job_role\"].astype(str) + \"__\" + df[\"exp_level\"].astype(str))\n",
    "        df[\"role_exp\"] = df[\"role_exp\"].astype(\"category\")\n",
    "    print(\"Added interactions:\", [c for c in [\"edu_industry\",\"role_exp\"] if c in df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (799736, 11) (799736,)\n",
      "Test  shapes: (199934, 11) (199934,)\n"
     ]
    }
   ],
   "source": [
    "#cell 7: fefine final X columns & Split \n",
    "extra_cat = [c for c in [\"edu_industry\",\"role_exp\"] if c in df.columns]\n",
    "categorical_model_cols = categorical_cols + extra_cat\n",
    "\n",
    "X_base_cols = categorical_model_cols + numeric_cols + [\"exp_level\",\"near_cbd\"]\n",
    "\n",
    "#outlier flags as weak signals:\n",
    "USE_OUTLIER_FLAGS = False\n",
    "if USE_OUTLIER_FLAGS:\n",
    "    X_base_cols += outlier_cols\n",
    "\n",
    "#remove target & log target if they slipped in\n",
    "X_base_cols = [c for c in X_base_cols if c not in [target, \"log_salary\"]]\n",
    "\n",
    "#drop rows with missing target\n",
    "keep_mask = df[target].notna()\n",
    "df_use = df.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "X = df_use[X_base_cols].copy()\n",
    "y = df_use[target].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Train shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Test  shapes:\", X_test.shape,  y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare-category bucketing applied where needed (threshold=10). Columns: ['job_role', 'industry', 'edu_industry', 'role_exp']\n"
     ]
    }
   ],
   "source": [
    "#cell 8: Rare-category bucketing (train-driven)\n",
    "APPLY_RARE_BUCKETING = True\n",
    "RARE_THRESH = 10  # categories with < RARE_THRESH occurrences in train -> \"__OTHER__\"\n",
    "\n",
    "#capture which categories were considered rare per column on TRAIN\n",
    "rare_map = {}  # {col_name: [rare_levels_as_str]}\n",
    "\n",
    "if APPLY_RARE_BUCKETING:\n",
    "    for c in categorical_model_cols + [\"exp_level\"]:\n",
    "        if c in X_train.columns:\n",
    "            vc = X_train[c].astype(str).value_counts()\n",
    "            rare = list(vc[vc < RARE_THRESH].index)\n",
    "            if rare:\n",
    "                rare_map[c] = rare\n",
    "\n",
    "                X_train[c] = X_train[c].astype(str).where(~X_train[c].astype(str).isin(rare), \"__OTHER__\")\n",
    "                X_test[c]  = X_test[c].astype(str).where(~X_test[c].astype(str).isin(rare), \"__OTHER__\")\n",
    "\n",
    "                # keep dtype tidy\n",
    "                X_train[c] = X_train[c].astype(\"category\")\n",
    "                X_test[c]  = X_test[c].astype(\"category\")\n",
    "\n",
    "    print(f\"Rare-category bucketing applied where needed (threshold={RARE_THRESH}). Columns: {list(rare_map.keys())}\")\n",
    "else:\n",
    "    rare_map = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerics to scale: ['years_experience', 'distance_from_cbd']\n",
      "Categoricals to OHE: ['company_id', 'job_role', 'education', 'major', 'industry', 'edu_industry', 'role_exp', 'exp_level']\n",
      "Binary passthrough: ['near_cbd']\n",
      "OHE drop mode: None\n"
     ]
    }
   ],
   "source": [
    "#cell 9: preprocessing(OHE)\n",
    "def _ohe(handle_unknown=\"ignore\", make_sparse=True, drop=None):\n",
    "    \"\"\"Return a OneHotEncoder that works across sklearn versions.\"\"\"\n",
    "    major, minor = (int(x) for x in sklearn_version.split(\".\")[:2])\n",
    "    kwargs = dict(handle_unknown=handle_unknown)\n",
    "    if drop is not None:  # eg \"if_binary\" for linear models' full-rank design\n",
    "        kwargs[\"drop\"] = drop\n",
    "    if (major, minor) >= (1, 2):\n",
    "        kwargs[\"sparse_output\"] = make_sparse\n",
    "    else:\n",
    "        kwargs[\"sparse\"] = make_sparse\n",
    "    return OneHotEncoder(**kwargs)\n",
    "\n",
    "# include exp_level in OHE; pass through near_cbd (no scaling)\n",
    "cat_for_ohe = [c for c in categorical_model_cols + [\"exp_level\"] if c in X_train.columns]\n",
    "num_for_scale = [c for c in numeric_cols if c in X_train.columns]\n",
    "bin_passthrough = [c for c in [\"near_cbd\"] if c in X_train.columns]\n",
    "\n",
    "\n",
    "DROP_IF_BINARY = False\n",
    "drop_mode = \"if_binary\" if DROP_IF_BINARY else None\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=True, with_std=True), num_for_scale),\n",
    "        (\"cat\", _ohe(make_sparse=True, drop=drop_mode), cat_for_ohe),\n",
    "        (\"bin\", \"passthrough\", bin_passthrough),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "print(\"Numerics to scale:\", num_for_scale)\n",
    "print(\"Categoricals to OHE:\", cat_for_ohe)\n",
    "print(\"Binary passthrough:\", bin_passthrough)\n",
    "print(\"OHE drop mode:\", drop_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transformed features: 162\n",
      "First 20 feature names: ['years_experience', 'distance_from_cbd', 'company_id_COMP0', 'company_id_COMP1', 'company_id_COMP10', 'company_id_COMP11', 'company_id_COMP12', 'company_id_COMP13', 'company_id_COMP14', 'company_id_COMP15', 'company_id_COMP16', 'company_id_COMP17', 'company_id_COMP18', 'company_id_COMP19', 'company_id_COMP2', 'company_id_COMP20', 'company_id_COMP21', 'company_id_COMP22', 'company_id_COMP23', 'company_id_COMP24']\n"
     ]
    }
   ],
   "source": [
    "#cell 10: Fit & Build Stable Feature Names \n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "feature_names = []\n",
    "\n",
    "# numeric names (same order as in num_for_scale)\n",
    "feature_names += num_for_scale\n",
    "\n",
    "# OHE names\n",
    "ohe = preprocessor.named_transformers_[\"cat\"]\n",
    "ohe_names = list(ohe.get_feature_names_out(cat_for_ohe))\n",
    "feature_names += ohe_names\n",
    "\n",
    "# passthrough (binary flags)\n",
    "bin_cols = []\n",
    "for name, trans, cols in preprocessor.transformers_:\n",
    "    if name == \"bin\":\n",
    "        bin_cols = list(cols)\n",
    "        break\n",
    "feature_names += bin_cols\n",
    "\n",
    "print(\"Total transformed features:\", len(feature_names))\n",
    "print(\"First 20 feature names:\", feature_names[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed shapes (X_train_t, X_test_t): (799736, 162) (199934, 162)\n"
     ]
    }
   ],
   "source": [
    "#cell 11: Transform Datasets \n",
    "X_train_t = preprocessor.transform(X_train)\n",
    "X_test_t  = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Transformed shapes (X_train_t, X_test_t):\", X_train_t.shape, X_test_t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_t is sparse: True\n",
      "\n",
      "Avg salary by exp_level:\n",
      " exp_level\n",
      "junior     96.960881\n",
      "mid       138.044550\n",
      "senior    132.193247\n",
      "Name: salary_in_thousands, dtype: float64\n",
      "\n",
      "Avg salary near_cbd=0/1:\n",
      " near_cbd\n",
      "0    125.158025\n",
      "1    134.227061\n",
      "Name: salary_in_thousands, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#cell 12: diagnostics / sanity Checks\n",
    "from scipy import sparse\n",
    "\n",
    "# 1) no leakage in raw X\n",
    "assert target not in X_train.columns and \"log_salary\" not in X_train.columns, \"Target/leakage in X!\"\n",
    "\n",
    "# 2) sparse/dense type\n",
    "print(\"X_train_t is sparse:\", sparse.issparse(X_train_t))\n",
    "\n",
    "# 3) quick business sanity: avg salary by exp_level (monotonic-ish expectation)\n",
    "if \"exp_level\" in df_use.columns:\n",
    "    g = df_use.groupby(\"exp_level\")[target].mean().reindex([\"junior\",\"mid\",\"senior\"])\n",
    "    print(\"\\nAvg salary by exp_level:\\n\", g)\n",
    "\n",
    "# 4) distance effect: near_cbd vs salary\n",
    "if \"near_cbd\" in df_use.columns:\n",
    "    print(\"\\nAvg salary near_cbd=0/1:\\n\", df_use.groupby(\"near_cbd\")[target].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-variance check passed: none found.\n"
     ]
    }
   ],
   "source": [
    "#cell 13: zero-variance check (on transformed train)\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "if sparse.issparse(X_train_t):\n",
    "    nnz_per_col = np.diff(X_train_t.tocsc().indptr)\n",
    "    zero_var_cols = np.where(nnz_per_col == 0)[0]\n",
    "else:\n",
    "    zero_var_cols = np.where(X_train_t.std(axis=0) == 0)[0]\n",
    "\n",
    "if len(zero_var_cols):\n",
    "    print(\"WARNING: zero-variance columns in transformed X_train_t:\", len(zero_var_cols))\n",
    "else:\n",
    "    print(\"Zero-variance check passed: none found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifacts to: /Users/yongryan/Downloads/bigdataryan /artifacts/prepared\n"
     ]
    }
   ],
   "source": [
    "#cell 14: persist Artifacts (preprocessor, splits, meta)\n",
    "ART_DIR = Path(\"artifacts/prepared\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# X_train_t = preprocessor.transform(X_train)\n",
    "# X_test_t  = preprocessor.transform(X_test)\n",
    "\n",
    "joblib.dump(preprocessor, ART_DIR / \"preprocessor.joblib\")\n",
    "\n",
    "joblib.dump(\n",
    "    {\"X_train_t\": X_train_t, \"X_test_t\": X_test_t, \"y_train\": y_train, \"y_test\": y_test},\n",
    "    ART_DIR / \"dataset_splits.joblib\"\n",
    ")\n",
    "\n",
    "feature_meta = {\n",
    "    \"feature_names\": feature_names,\n",
    "    \"ohe_feature_names\": ohe_names,\n",
    "    \"cat_for_ohe\": cat_for_ohe,\n",
    "    \"num_for_scale\": num_for_scale,\n",
    "    \"bin_cols\": bin_cols,\n",
    "    \"categorical_model_cols\": categorical_model_cols,\n",
    "    \"used_interactions\": [c for c in [\"edu_industry\",\"role_exp\"] if c in X_train.columns],\n",
    "    \"rare_bucketing\": {\n",
    "        \"applied\": bool(rare_map),\n",
    "        \"threshold\": RARE_THRESH if APPLY_RARE_BUCKETING else None,\n",
    "        \"rare_map\": rare_map,  # exact rare levels per column learned on TRAIN\n",
    "    },\n",
    "    \"ohe_drop_mode\": drop_mode,\n",
    "}\n",
    "\n",
    "joblib.dump(feature_meta, ART_DIR / \"feature_meta.joblib\")\n",
    "print(\"Saved artifacts to:\", ART_DIR.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAIE Project (.venv)",
   "language": "python",
   "name": "caie_project_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
